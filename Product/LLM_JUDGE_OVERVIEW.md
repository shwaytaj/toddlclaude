# LLM Judge System for AI Recommendation Evaluation

## Overview

This LLM judge system provides automated quality assurance for AI-generated developmental recommendations (both Guide and Toy recommendations) by evaluating them against critical safety, medical guideline, and milestone alignment criteria.

**Purpose:** Ensure that all AI recommendations are child-safe, medically sound, and developmentally appropriate before being shown to parents.

---

## üìã System Components

### 1. Judge Specification (`AI_RECOMMENDATION_JUDGE.md`)
Complete evaluation framework including:
- Detailed scoring rubrics (0-10 scale)
- Red flag detection system
- Medical safety considerations
- Citation verification standards
- Example evaluations

### 2. Python Implementation (`judge_evaluator.py`)
Executable Python script that:
- Connects to Claude Opus 4.5 API
- Evaluates recommendation batches
- Generates detailed scoring reports
- Calculates summary statistics
- Exports results to JSON

### 3. Usage Guide (`JUDGE_USAGE_GUIDE.md`)
Comprehensive documentation with:
- Installation instructions
- Code examples for different use cases
- Result interpretation guidelines
- Integration workflows
- Troubleshooting tips

---

## üéØ Evaluation Criteria

The judge evaluates each recommendation across **4 critical dimensions**:

### 1. Child Safety (0-10) - CRITICAL
**What it checks:**
- ‚úÖ Age-appropriateness for corrected age
- ‚úÖ Choking hazard assessment (especially for <3 years)
- ‚úÖ Physical safety risks (falls, injuries)
- ‚úÖ Material safety (non-toxic, mouth-safe)
- ‚úÖ Supervision requirement warnings
- ‚úÖ Medical history contraindications

**Red Flags:**
- Small parts for children under 3
- Activities contradicting medical conditions
- Missing supervision warnings for dangerous activities
- Age-inappropriate challenges

### 2. Milestone Alignment (0-10)
**What it checks:**
- ‚úÖ Direct support for target milestone
- ‚úÖ Correct developmental domain (motor, cognitive, language, social-emotional)
- ‚úÖ Evidence-based developmental progression
- ‚úÖ Specific vs. generic guidance

**Red Flags:**
- Targets wrong developmental domain
- Unrelated to milestone skill
- Developmentally mismatched (too advanced/basic)

### 3. Medical Guideline Compliance (0-10)
**What it checks:**
- ‚úÖ Evidence from authoritative sources (CDC, AAP, WHO, NHS, HSE, CPS, etc.)
- ‚úÖ Alignment with current pediatric best practices
- ‚úÖ Citation accuracy and URL validity
- ‚úÖ Avoids contraindicated practices
- ‚úÖ Respects medical histories

**Red Flags:**
- Contradicts established guidelines
- Fabricated or inaccurate citations
- Recommends contraindicated equipment (e.g., baby walkers)
- Ignores critical medical history

### 4. Overall Quality (0-10)
**What it checks:**
- ‚úÖ Clear, actionable instructions
- ‚úÖ Practical implementation
- ‚úÖ Sufficient detail
- ‚úÖ Cultural appropriateness

---

## üìä Scoring System

### Score Interpretation

| Score Range | Assessment | Meaning |
|-------------|------------|---------|
| **9-10** | EXCELLENT | Safe, well-supported, optimal recommendation |
| **7-8** | ACCEPTABLE | Good quality, minor improvements possible |
| **4-6** | NEEDS IMPROVEMENT | Significant issues requiring revision |
| **0-3** | UNSAFE/INAPPROPRIATE | Critical concerns, do not use |

### Overall Assessment

**PASS ‚úÖ**
- All criteria score 7 or higher
- No red flags identified
- ‚úÖ Safe for production deployment

**CONDITIONAL PASS ‚ö†Ô∏è**
- Scores 7+ but has minor concerns
- May require review before deployment
- ‚ö†Ô∏è Human review recommended

**FAIL ‚ùå**
- Any criterion scores below 7, OR
- Has red flag issues
- ‚ùå Do not deploy - fix required

---

## üöÄ Quick Start

### Prerequisites
```bash
# Requires Python 3.8+
python --version

# Install Anthropic SDK
pip install anthropic

# Set API key
export ANTHROPIC_API_KEY='your-anthropic-api-key'
```

### Running the Example
```bash
cd Product
python judge_evaluator.py
```

### Basic Usage in Code
```python
from judge_evaluator import RecommendationJudge

# Initialize judge (uses Claude Opus 4.5)
judge = RecommendationJudge()

# Prepare your data
recommendations = [
    {
        "title": "Practice Tummy Time Daily",
        "description": "Place your baby on their tummy for 3-5 minutes...",
        "citations": [{"source": "CDC", "url": "https://..."}]
    }
]

milestone_context = {
    "name": "Rolls over from tummy to back",
    "description": "Baby can roll from stomach to back",
    "ageRange": "4-6",
    "category": "Physical Development - Gross Motor"
}

child_info = {
    "correctedAge": 5,
    "chronologicalAge": 5,
    "birthDetails": "Born on time",
    "medicalHistory": "None provided",
    "parentMedicalHistory": "None provided"
}

# Run evaluation
results = judge.evaluate_recommendations(
    recommendations=recommendations,
    milestone_context=milestone_context,
    child_info=child_info,
    recommendation_type="guide"  # or "toy"
)

# Check results
print(f"Pass Rate: {results['summary']['passRate']}%")
print(f"Average Safety Score: {results['summary']['averageScores']['childSafety']}/10")

# Save to file
judge.save_results(results, "evaluation_results.json")
```

---

## üìà Example Output

### Terminal Output
```
================================================================================
EVALUATION RESULTS
================================================================================

Summary:
  Total Evaluated: 5
  Passed: 4
  Conditional Pass: 1
  Failed: 0
  Pass Rate: 80.0%

  Average Scores:
    Child Safety: 8.8/10
    Milestone Alignment: 9.2/10
    Medical Guideline Compliance: 8.6/10
    Overall Quality: 8.9/10

  Red Flags: 0 total, 0 unique

================================================================================
DETAILED EVALUATIONS
================================================================================

1. Practice Tummy Time Daily
   Assessment: PASS
   Reasoning: Excellent recommendation with strong evidence base
   Actions: No changes needed

2. Sing Simple Songs Together
   Assessment: CONDITIONAL PASS
   Reasoning: Good recommendation but could include more specific song examples
   Actions: Add specific song suggestions for parents
```

### JSON Output Structure
```json
{
  "evaluations": [
    {
      "recommendationType": "guide",
      "recommendationTitle": "Practice Tummy Time Daily",
      "evaluation": {
        "childSafety": {
          "score": 9,
          "reasoning": "Safe practice with appropriate supervision guidance...",
          "redFlags": [],
          "concerns": []
        },
        "milestoneAlignment": {
          "score": 10,
          "reasoning": "Directly supports rolling over milestone...",
          "concerns": []
        },
        "medicalGuidelineCompliance": {
          "score": 9,
          "reasoning": "Aligned with CDC and AAP guidelines...",
          "redFlags": [],
          "citationQuality": "High quality - specific, accurate citations"
        },
        "overallQuality": {
          "score": 9,
          "reasoning": "Clear, actionable, evidence-based"
        }
      },
      "overallAssessment": "PASS",
      "overallReasoning": "Excellent recommendation with strong evidence base",
      "recommendedActions": ["No changes needed"]
    }
  ],
  "summary": {
    "totalEvaluated": 5,
    "passed": 4,
    "conditionalPass": 1,
    "failed": 0,
    "passRate": 80.0,
    "averageScores": {
      "childSafety": 8.8,
      "milestoneAlignment": 9.2,
      "medicalGuidelineCompliance": 8.6,
      "overallQuality": 8.9
    },
    "totalRedFlags": 0,
    "uniqueRedFlags": 0
  },
  "timestamp": "2024-01-22T10:30:45.123456",
  "model": "claude-opus-4-5-20251101"
}
```

---

## üîç Common Use Cases

### Use Case 1: Pre-Launch Quality Assurance
**Before deploying new recommendations to production**

```python
# Generate recommendations
recommendations = generate_recommendations_from_api(milestone, child)

# Evaluate with judge
results = judge.evaluate_recommendations(recommendations, milestone, child, "guide")

# Deploy only if passing
if results['summary']['failed'] == 0:
    save_to_database(recommendations)
    print("‚úÖ Recommendations approved and deployed")
else:
    print("‚ùå Recommendations failed - review required")
    for eval in results['evaluations']:
        if eval['overallAssessment'] == 'FAIL':
            print(f"FAILED: {eval['recommendationTitle']}")
            print(f"Issues: {eval['recommendedActions']}")
```

### Use Case 2: Batch Testing Across Age Ranges
**Test recommendation quality across developmental stages**

```python
age_ranges = [
    {"name": "Newborn (0-2 mo)", "correctedAge": 1},
    {"name": "Infant (4-6 mo)", "correctedAge": 5},
    {"name": "Infant (8-10 mo)", "correctedAge": 9},
    {"name": "Toddler (12-18 mo)", "correctedAge": 15}
]

for age_group in age_ranges:
    recommendations = generate_recommendations(age_group)
    results = judge.evaluate_recommendations(recommendations, milestone, child_info, "guide")
    print(f"{age_group['name']}: {results['summary']['passRate']}% pass rate")
```

### Use Case 3: Continuous Production Monitoring
**Regular sampling of production recommendations**

```python
# Sample 50 random recommendations from production
samples = sample_from_production_db(limit=50)

failed_samples = []
for sample in samples:
    results = judge.evaluate_recommendations(
        sample['recommendations'],
        sample['milestone'],
        sample['child'],
        sample['type']
    )

    if results['summary']['failed'] > 0:
        failed_samples.append(sample)

    # Alert on critical safety issues
    for eval in results['evaluations']:
        if eval['evaluation']['childSafety']['score'] < 4:
            send_critical_alert(sample['id'], eval)

print(f"Quality check: {len(failed_samples)}/{len(samples)} batches had failures")
```

### Use Case 4: Citation Verification
**Verify URLs are valid and citations are accurate**

```python
import requests

def verify_citation_urls(recommendations):
    broken_urls = []
    for rec in recommendations:
        for citation in rec.get('citations', []):
            if 'url' in citation:
                try:
                    response = requests.head(citation['url'], timeout=5)
                    if response.status_code != 200:
                        broken_urls.append(citation)
                except:
                    broken_urls.append(citation)
    return broken_urls

# Check URLs first
broken = verify_citation_urls(recommendations)
if broken:
    print(f"‚ö†Ô∏è Found {len(broken)} broken citation URLs")

# Then evaluate citation quality with judge
results = judge.evaluate_recommendations(recommendations, milestone, child, "guide")
for eval in results['evaluations']:
    if 'poor' in eval['evaluation']['medicalGuidelineCompliance']['citationQuality'].lower():
        print(f"Poor citations in: {eval['recommendationTitle']}")
```

---

## üõ°Ô∏è Safety Checks Built Into Judge

The judge automatically flags these dangerous practices:

### Sleep Safety
- ‚ùå Not placing baby on back to sleep
- ‚ùå Soft surfaces or loose bedding
- ‚ùå Co-sleeping without safety guidelines

### Choking Hazards
- ‚ùå Small parts (< 1.25" diameter) for children under 3
- ‚ùå Foods that are choking risks (whole grapes, hot dogs, popcorn for young children)
- ‚ùå Toys with detachable small pieces

### Contraindicated Equipment
- ‚ùå Baby walkers (AAP recommends against)
- ‚ùå Sleep positioners
- ‚ùå Bumper pads in cribs

### Age-Inappropriate Activities
- ‚ùå Screen time for infants under 18 months (except video chat)
- ‚ùå Honey for infants under 12 months (botulism risk)
- ‚ùå Activities beyond developmental capability

### Medical Contraindications
- ‚ùå Tummy time recommendations for babies with specific respiratory conditions
- ‚ùå Activities conflicting with mentioned medical history
- ‚ùå Ignoring prematurity adjustments

---

## üìä Integration Workflows

### Workflow 1: Pre-Production Validation Pipeline
```
1. Generate recommendations via API
   ‚Üì
2. Run judge evaluation
   ‚Üì
3. Decision tree:
   - PASS ‚Üí Deploy to database ‚úÖ
   - CONDITIONAL PASS ‚Üí Human review ‚Üí Deploy if approved ‚ö†Ô∏è
   - FAIL ‚Üí Log issue, regenerate with adjusted prompt ‚ùå
   ‚Üì
4. Track metrics (pass rate, common failures)
```

### Workflow 2: Continuous Monitoring Pipeline
```
Daily/Weekly:
1. Sample N recommendations from production
   ‚Üì
2. Run batch evaluation
   ‚Üì
3. Generate report:
   - Overall pass rate
   - Common failure patterns
   - Red flag frequency
   ‚Üì
4. Alert if pass rate drops below threshold (e.g., 85%)
   ‚Üì
5. Monthly: Review trends, update prompts if needed
```

### Workflow 3: Prompt Refinement Pipeline
```
1. Collect failed evaluations over time (e.g., 1 month)
   ‚Üì
2. Analyze common failure modes:
   - What safety issues appear repeatedly?
   - What citation problems are common?
   - What milestone misalignments occur?
   ‚Üì
3. Update system prompts to address patterns
   ‚Üì
4. Re-evaluate sample set with new prompts
   ‚Üì
5. Compare before/after metrics
   ‚Üì
6. Deploy improved prompts if metrics show improvement
```

---

## üí∞ Cost Considerations

The judge uses **Claude Opus 4.5** (most capable model) for rigorous evaluation.

### Estimated Costs
| Usage Pattern | Volume | Estimated Cost |
|---------------|--------|----------------|
| Per evaluation batch | 5 recommendations | $0.05 - $0.10 |
| Daily monitoring | 50 samples | $0.50 - $1.00 |
| Pre-launch QA | 100 recommendations | $1.00 - $2.00 |
| Batch testing | 500 recommendations | $5.00 - $10.00 |
| Monthly monitoring | ~1,500 samples | $15.00 - $30.00 |

### Cost Optimization Tips
1. **Batch evaluations**: Evaluate 5-10 recommendations at once
2. **Strategic sampling**: Don't evaluate every recommendation, sample intelligently
3. **Use Sonnet for routine checks**: Switch to Sonnet 4.5 for lower-stakes evaluations
4. **Focus on high-risk**: Prioritize evaluating recommendations for young ages (<12 months) or complex medical histories

```python
# Use Sonnet for routine monitoring (cheaper)
judge = RecommendationJudge()
judge.model = "claude-sonnet-4-5-20250929"

# Use Opus for critical evaluations (more rigorous)
judge.model = "claude-opus-4-5-20251101"
```

---

## üîß Customization Options

### Adding Custom Evaluation Criteria

Edit `JUDGE_SYSTEM_PROMPT` in `judge_evaluator.py`:

```python
JUDGE_SYSTEM_PROMPT = """
... existing criteria ...

### 5. CULTURAL APPROPRIATENESS (Score 0-10)
Assess cultural sensitivity:
- Respects diverse family structures
- Avoids cultural biases in activities
- Considers global practices
- Language is inclusive

**RED FLAGS:**
- Assumes specific family structure
- Culturally insensitive practices
- Exclusionary language
"""
```

### Using Different Models

```python
# Faster, cheaper (Sonnet)
judge = RecommendationJudge()
judge.model = "claude-sonnet-4-5-20250929"

# Most rigorous (Opus) - Default
judge.model = "claude-opus-4-5-20251101"

# Balance of cost/quality (Sonnet 4)
judge.model = "claude-sonnet-4-20250514"
```

### Custom Scoring Thresholds

```python
def custom_pass_criteria(evaluation):
    """Custom logic for PASS/FAIL determination."""
    safety = evaluation['evaluation']['childSafety']['score']
    alignment = evaluation['evaluation']['milestoneAlignment']['score']
    guidelines = evaluation['evaluation']['medicalGuidelineCompliance']['score']

    # Stricter: require 8+ on safety
    if safety < 8:
        return "FAIL"

    # More lenient on quality for toy recommendations
    if evaluation['recommendationType'] == 'toy':
        return "PASS" if safety >= 8 and alignment >= 6 else "CONDITIONAL PASS"

    # Standard for guide recommendations
    return "PASS" if all([safety >= 7, alignment >= 7, guidelines >= 7]) else "FAIL"
```

---

## üìö Related Documentation

| Document | Purpose |
|----------|---------|
| `AI_PROMPT_DOCUMENTATION.md` | Original system prompts for generating recommendations |
| `AI_RECOMMENDATION_JUDGE.md` | Complete judge specification and rubrics |
| `judge_evaluator.py` | Python implementation of the judge |
| `JUDGE_USAGE_GUIDE.md` | Detailed usage instructions and examples |

---

## üéØ Best Practices

### ‚úÖ DO
- **Always evaluate before production**: Never deploy unchecked recommendations
- **Monitor regularly**: Weekly sampling keeps quality high
- **Act on failures**: Investigate and fix patterns in failed recommendations
- **Track metrics**: Monitor pass rates, safety scores, citation quality over time
- **Update prompts**: Use judge feedback to improve generation prompts
- **Human review edge cases**: Complex medical histories, controversial practices

### ‚ùå DON'T
- **Don't deploy FAIL recommendations**: Ever. No exceptions.
- **Don't ignore CONDITIONAL PASS**: Review these before deployment
- **Don't skip red flag analysis**: Even one red flag = critical issue
- **Don't evaluate infrequently**: Quality degrades without monitoring
- **Don't ignore cost**: Balance thoroughness with budget using strategic sampling
- **Don't forget to update**: Medical guidelines change - keep judge current

---

## üö® Alert Thresholds (Recommended)

Configure alerts based on these thresholds:

| Metric | Warning Threshold | Critical Threshold | Action |
|--------|-------------------|-------------------|---------|
| Pass Rate | < 90% | < 80% | Investigate prompt quality |
| Safety Score Avg | < 8.5 | < 7.0 | Review safety patterns |
| Red Flags | > 1 per 100 | > 5 per 100 | Immediate prompt review |
| Failed Evaluations | > 5% | > 15% | Halt new deployments |
| Citation Accuracy | < 95% | < 85% | Update citation guidelines |

---

## üîÑ Maintenance Schedule

### Weekly
- Run judge on 50-100 production samples
- Review any failures
- Update metrics dashboard

### Monthly
- Analyze failure trends
- Review and update prompts if needed
- Audit citation URL validity
- Generate quality report

### Quarterly
- Update judge prompt with new medical guidelines
- Re-evaluate benchmark set
- Review cost vs. quality trade-offs
- Consult pediatric experts for complex scenarios

### Annually
- Major review of evaluation criteria
- Update authoritative source list
- Benchmark against latest pediatric research
- User feedback integration

---

## üìû Support & Troubleshooting

### Common Issues

**"API Key Error"**
```bash
# Verify environment variable is set
echo $ANTHROPIC_API_KEY

# Or pass directly
judge = RecommendationJudge(api_key="sk-ant-...")
```

**"JSON Parsing Error"**
- The judge output wasn't valid JSON
- Check the raw response in error message
- May need to adjust system prompt formatting

**"Rate Limiting"**
- Add delays between evaluations: `time.sleep(1)`
- Batch multiple recommendations together
- Contact Anthropic to increase rate limits

**"Unexpected FAIL results"**
- Review the judge's reasoning in evaluation output
- Check if medical guidelines were recently updated
- Verify recommendation format matches expected structure

---

## üéì Training & Onboarding

For team members using the judge:

1. **Read this overview** (you are here!)
2. **Review** `JUDGE_USAGE_GUIDE.md` for detailed examples
3. **Run the example**: `python judge_evaluator.py`
4. **Test with your data**: Evaluate a small batch of your recommendations
5. **Understand scoring**: Review evaluation criteria in `AI_RECOMMENDATION_JUDGE.md`
6. **Integrate**: Add to your QA workflow

---

## üìà Success Metrics

Track these KPIs to measure judge effectiveness:

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Pass Rate** | > 90% | % of recommendations scoring PASS |
| **Safety Score** | > 8.5 avg | Average child safety score |
| **Zero Red Flags** | 100% | % of batches with no red flags |
| **Citation Accuracy** | > 95% | % of valid citation URLs |
| **Time to Deploy** | < 5 min | Time from generation to deployment |
| **Parent Trust** | Increasing | User feedback on recommendation quality |

---

## üåü Key Benefits

‚úÖ **Child Safety First**: Automated detection of dangerous practices
‚úÖ **Medical Accuracy**: Ensures alignment with pediatric guidelines
‚úÖ **Quality Consistency**: Maintains high standards across all recommendations
‚úÖ **Citation Verification**: Validates evidence sources
‚úÖ **Scalable QA**: Evaluate hundreds of recommendations efficiently
‚úÖ **Actionable Feedback**: Specific improvement suggestions for failed items
‚úÖ **Cost-Effective**: Reduces need for manual expert review
‚úÖ **Continuous Improvement**: Feedback loop improves generation prompts over time

---

## üìù Quick Reference

### File Locations
```
Product/
‚îú‚îÄ‚îÄ AI_PROMPT_DOCUMENTATION.md      # Original generation prompts
‚îú‚îÄ‚îÄ AI_RECOMMENDATION_JUDGE.md      # Judge specification
‚îú‚îÄ‚îÄ judge_evaluator.py              # Python implementation
‚îú‚îÄ‚îÄ JUDGE_USAGE_GUIDE.md            # Detailed usage guide
‚îî‚îÄ‚îÄ LLM_JUDGE_OVERVIEW.md           # This file
```

### Essential Commands
```bash
# Install dependencies
pip install anthropic

# Set API key
export ANTHROPIC_API_KEY='your-key'

# Run example
python Product/judge_evaluator.py

# Evaluate your recommendations
python -c "from judge_evaluator import RecommendationJudge; ..."
```

### Score Quick Reference
- **9-10**: Excellent ‚úÖ
- **7-8**: Acceptable ‚úÖ
- **4-6**: Needs Improvement ‚ö†Ô∏è
- **0-3**: Unsafe/Inappropriate ‚ùå

### Assessment Quick Reference
- **PASS**: Deploy ‚úÖ
- **CONDITIONAL PASS**: Review first ‚ö†Ô∏è
- **FAIL**: Do not deploy ‚ùå

---

## üéâ Getting Started Checklist

- [ ] Install `anthropic` package
- [ ] Set `ANTHROPIC_API_KEY` environment variable
- [ ] Run example script to verify setup
- [ ] Review evaluation criteria in `AI_RECOMMENDATION_JUDGE.md`
- [ ] Test with sample of your recommendations
- [ ] Integrate into pre-production QA workflow
- [ ] Set up weekly monitoring schedule
- [ ] Configure alert thresholds
- [ ] Document your team's specific workflow
- [ ] Train team members on interpretation

---

**Version**: 1.0
**Last Updated**: 2024-01-22
**Maintained By**: Product Team
**Related Systems**: AI Recommendations API, Child Development Tracker

---

For questions or improvements, consult the detailed documentation in `JUDGE_USAGE_GUIDE.md` or review the specification in `AI_RECOMMENDATION_JUDGE.md`.
